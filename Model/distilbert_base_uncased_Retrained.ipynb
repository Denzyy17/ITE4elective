{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cc05731b76314d229e4bf1de74464231":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6a077e38890406ea1ce60865586c05c","IPY_MODEL_d6b21d551c3e40c992714410919190c0","IPY_MODEL_d167da468af344d1a4e54077a9269bf6"],"layout":"IPY_MODEL_541f6a1404dd4af0bdfc110ebddeee35"}},"c6a077e38890406ea1ce60865586c05c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7696cad188684bd19c354f088bb2d70c","placeholder":"​","style":"IPY_MODEL_693587cbb5934dab9ea976163b35da00","value":"Casting the dataset: 100%"}},"d6b21d551c3e40c992714410919190c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_753bf99929784d35b1299d6378c66840","max":10698,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a5aa6b7225849ec9e2d46a1df641f37","value":10698}},"d167da468af344d1a4e54077a9269bf6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab788078753643e991cb23a29782a908","placeholder":"​","style":"IPY_MODEL_852a969caf0c4f2097d376f14965bffe","value":" 10698/10698 [00:00&lt;00:00, 54577.08 examples/s]"}},"541f6a1404dd4af0bdfc110ebddeee35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7696cad188684bd19c354f088bb2d70c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"693587cbb5934dab9ea976163b35da00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"753bf99929784d35b1299d6378c66840":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a5aa6b7225849ec9e2d46a1df641f37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab788078753643e991cb23a29782a908":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"852a969caf0c4f2097d376f14965bffe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64fe7ee2d6f84144a446fff13ec6b11b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00a0affddf894af38b662794b1f83e33","IPY_MODEL_38ff27bcf35e4ea9ae1ac4fd5c6b0cd6","IPY_MODEL_dc860a38ad1e43dba98c31c1d923b167"],"layout":"IPY_MODEL_75738e2a8a1d45bdab24f35d52a1bf77"}},"00a0affddf894af38b662794b1f83e33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f023fc39ccf4635a310df6e006935c2","placeholder":"​","style":"IPY_MODEL_5e160e3de1914fe4ab3c6f4bc2201523","value":"Map: 100%"}},"38ff27bcf35e4ea9ae1ac4fd5c6b0cd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7100629e4d0d4b2e86c8cca08bd03a77","max":8558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0eb2f7e495f47a180e87ef80488ed3b","value":8558}},"dc860a38ad1e43dba98c31c1d923b167":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f68bb947557423480259effa3651c1b","placeholder":"​","style":"IPY_MODEL_9cb0db235e4c454780a618a2eaaa8967","value":" 8558/8558 [00:07&lt;00:00, 1326.33 examples/s]"}},"75738e2a8a1d45bdab24f35d52a1bf77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f023fc39ccf4635a310df6e006935c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e160e3de1914fe4ab3c6f4bc2201523":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7100629e4d0d4b2e86c8cca08bd03a77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0eb2f7e495f47a180e87ef80488ed3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f68bb947557423480259effa3651c1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cb0db235e4c454780a618a2eaaa8967":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1261a2f183b4d0b9f562281f9c9a913":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11db8716bde144719fde1594f7139855","IPY_MODEL_c77d4fd7ceed44b19c66c50154885b8a","IPY_MODEL_dba3b694ea9149608df4a6980308f4a9"],"layout":"IPY_MODEL_624c450702d8403c87dc3ae150c079b8"}},"11db8716bde144719fde1594f7139855":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1abe1c8c6a249d691346720ff4193d7","placeholder":"​","style":"IPY_MODEL_0f3fb7cc7a4345d2a1af19c398325922","value":"Map: 100%"}},"c77d4fd7ceed44b19c66c50154885b8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03e8fb8cd96945e1a727cdcb7dcbd1b4","max":2140,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43801b67fa194baeb1fc7ba6cd89b348","value":2140}},"dba3b694ea9149608df4a6980308f4a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbc58a19c64246f38933d2111a943966","placeholder":"​","style":"IPY_MODEL_0f9abcacb43e4bf89b55fbb43b22b4a4","value":" 2140/2140 [00:01&lt;00:00, 1386.38 examples/s]"}},"624c450702d8403c87dc3ae150c079b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1abe1c8c6a249d691346720ff4193d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f3fb7cc7a4345d2a1af19c398325922":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03e8fb8cd96945e1a727cdcb7dcbd1b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43801b67fa194baeb1fc7ba6cd89b348":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbc58a19c64246f38933d2111a943966":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f9abcacb43e4bf89b55fbb43b22b4a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d07b784f600543158dff979ee900e2cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b0a7716cfe04dcca2458a7485f6edb5","IPY_MODEL_c6080593f6bb472193fd10310d338bad","IPY_MODEL_c03ffd379d0a4d16b8b51eb9deb86a41"],"layout":"IPY_MODEL_194b4d1f3f504cca962cd3c6196571f0"}},"9b0a7716cfe04dcca2458a7485f6edb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97543aedaa69404984a7aaa541af8e29","placeholder":"​","style":"IPY_MODEL_35b22545f10e4f0a8670f91f71d83792","value":"model.safetensors: 100%"}},"c6080593f6bb472193fd10310d338bad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b80ee31afa7146aab796d09ef2c74c91","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bc7e0f573e44e9588f194af2efa0edf","value":267954768}},"c03ffd379d0a4d16b8b51eb9deb86a41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc224fd1822f4f55a00be242327de8d6","placeholder":"​","style":"IPY_MODEL_5c55ccb4339d42e492a444cb4ee3fdd3","value":" 268M/268M [00:01&lt;00:00, 189MB/s]"}},"194b4d1f3f504cca962cd3c6196571f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97543aedaa69404984a7aaa541af8e29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35b22545f10e4f0a8670f91f71d83792":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b80ee31afa7146aab796d09ef2c74c91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bc7e0f573e44e9588f194af2efa0edf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc224fd1822f4f55a00be242327de8d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c55ccb4339d42e492a444cb4ee3fdd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3a9b10bada94c2d88c5d144730705cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fea5512d85c4ee485a33348606da167","IPY_MODEL_74f6166495c64df6944fcd70b6e7f6a0","IPY_MODEL_a3c9b76def104da8aebab6a88eaa7c91"],"layout":"IPY_MODEL_09fda26765fa4fd6aad01b818d326d72"}},"6fea5512d85c4ee485a33348606da167":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb37a4a6e0494fa6aa5050083292a5ae","placeholder":"​","style":"IPY_MODEL_a063457692e3409abd69c243c1ba200b","value":"Casting the dataset: 100%"}},"74f6166495c64df6944fcd70b6e7f6a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02b954ed9766457fafb3b5964831748c","max":10698,"min":0,"orientation":"horizontal","style":"IPY_MODEL_234f875582284bf7b98af4b9d0fdd89d","value":10698}},"a3c9b76def104da8aebab6a88eaa7c91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f4cdfd0a9264ca687e5deaf6c4eb30e","placeholder":"​","style":"IPY_MODEL_e4a7053bb02447ceb1ac2150fc8323ea","value":" 10698/10698 [00:00&lt;00:00, 163705.98 examples/s]"}},"09fda26765fa4fd6aad01b818d326d72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb37a4a6e0494fa6aa5050083292a5ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a063457692e3409abd69c243c1ba200b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02b954ed9766457fafb3b5964831748c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"234f875582284bf7b98af4b9d0fdd89d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f4cdfd0a9264ca687e5deaf6c4eb30e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4a7053bb02447ceb1ac2150fc8323ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c35c3b2ab6a4474b566c5993a5ac7c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ce972d8703e4012932a58120b90565d","IPY_MODEL_27091ace9e564e28841cc87884da096c","IPY_MODEL_4da2463133a34eb7830dd272b4e629cf"],"layout":"IPY_MODEL_0d232079246b494884d5039a34478e91"}},"7ce972d8703e4012932a58120b90565d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03ee53d1dc2840d4aa7a5672028709a9","placeholder":"​","style":"IPY_MODEL_f2dcaeba9fcd4c21af27aec81490d299","value":"Map: 100%"}},"27091ace9e564e28841cc87884da096c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2c5fc76948747809dd4b31ac6058094","max":8558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32c0f618593c4456a2c345f18c50eb8e","value":8558}},"4da2463133a34eb7830dd272b4e629cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c11fa59dbbd4dcaa2f31188e0d301e2","placeholder":"​","style":"IPY_MODEL_d0403ca11af446b2b23e4e93f032af77","value":" 8558/8558 [00:04&lt;00:00, 1975.59 examples/s]"}},"0d232079246b494884d5039a34478e91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03ee53d1dc2840d4aa7a5672028709a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2dcaeba9fcd4c21af27aec81490d299":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2c5fc76948747809dd4b31ac6058094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32c0f618593c4456a2c345f18c50eb8e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c11fa59dbbd4dcaa2f31188e0d301e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0403ca11af446b2b23e4e93f032af77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a8791b5be28485b8bb16d9f6922be5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7c4066b91c74c0080394cba1023d62f","IPY_MODEL_ab77d6797a4545d4b66127e19d324e49","IPY_MODEL_724556435b86447183f28207235db8ad"],"layout":"IPY_MODEL_23ac7263c0b0438896c15a00bee2e3c3"}},"a7c4066b91c74c0080394cba1023d62f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc21c7e1f3b043cf8f10ee72e04a377d","placeholder":"​","style":"IPY_MODEL_ecd4158e95c24f1690f87267ca80792e","value":"Map: 100%"}},"ab77d6797a4545d4b66127e19d324e49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e227fcd48c104b70a9550391dc7e822e","max":2140,"min":0,"orientation":"horizontal","style":"IPY_MODEL_683151a29ee64c38921a0e76ecf932aa","value":2140}},"724556435b86447183f28207235db8ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1497fadd90ca4f0abff553a2f171bf58","placeholder":"​","style":"IPY_MODEL_53a171db91da4454be3cabc7ef84010c","value":" 2140/2140 [00:01&lt;00:00, 1149.32 examples/s]"}},"23ac7263c0b0438896c15a00bee2e3c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc21c7e1f3b043cf8f10ee72e04a377d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecd4158e95c24f1690f87267ca80792e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e227fcd48c104b70a9550391dc7e822e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"683151a29ee64c38921a0e76ecf932aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1497fadd90ca4f0abff553a2f171bf58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53a171db91da4454be3cabc7ef84010c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["Distilbert"],"metadata":{"id":"BGM_iP-SFr_Z"}},{"cell_type":"code","source":["pip install transformers[torch] datasets optuna scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CboGT90tGBNj","outputId":"c5c65619-bdc9-4700-cbcb-e9aca036bf3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (4.67.1)\n","Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.8.0+cu126)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (1.11.0)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.1)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers[torch]) (2.5.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.3)\n"]}]},{"cell_type":"code","source":["pip install --upgrade transformers datasets accelerate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQ8P90oOGCxR","outputId":"59d039ef-cf6b-4b9e-e422-f662de2a0fe6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"]}]},{"cell_type":"code","source":["import optuna\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer\n",")\n","from datasets import load_dataset\n","import numpy as np\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"GNPweTxUFre3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from datasets import Dataset, DatasetDict, ClassLabel\n","from transformers import AutoTokenizer\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","# 1 Load dataset from local CSV\n","csv_file_path = 'Philippine_Business_TrustPilot_Reviews_Labeled.csv'\n","df_raw = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n","\n","# Rename columns for consistency with DistilBERT pipeline and map labels\n","df_raw = df_raw.rename(columns={'User Review Body': 'sentence', 'Ground Label': 'label'})\n","\n","# Map 'Positive' to 1, 'Negative' to 0, and filter out 'Neutral'\n","label_mapping = {'Positive': 1, 'Negative': 0}\n","# Use .loc to avoid SettingWithCopyWarning\n","df_filtered = df_raw.copy()\n","df_filtered['label'] = df_filtered['label'].map(label_mapping)\n","df_filtered = df_filtered.dropna(subset=['label']) # Drop rows where mapping resulted in NaN (e.g., 'Neutral')\n","df_filtered.loc[:, 'label'] = df_filtered['label'].astype(int) # Convert labels to int\n","\n","# Convert DataFrame to Hugging Face Dataset\n","dataset = Dataset.from_pandas(df_filtered)\n","\n","# Cast 'label' column to ClassLabel for stratification\n","features = dataset.features.copy()\n","features['label'] = ClassLabel(names=['negative', 'positive']) # Assuming 0=negative, 1=positive\n","dataset = dataset.cast(features)\n","\n","# Split into train and test/validation sets\n","# Since load_dataset(\"csv\") would typically create a single 'train' split, we manually create train/validation splits.\n","train_test_split = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=42)\n","dataset_dict = DatasetDict({\n","    'train': train_test_split['train'],\n","    'validation': train_test_split['test'] # Rename 'test' to 'validation' for consistency\n","})\n","\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","\n","def preprocess(examples):\n","    return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n","\n","# Apply preprocessing to the dataset dictionary\n","encoded_dataset = dataset_dict.map(preprocess, batched=True)\n","\n","# Rename the label column to 'labels' as expected by the Trainer\n","encoded_dataset = encoded_dataset.rename_column(\"label\", \"labels\")\n","encoded_dataset.set_format(\"torch\")\n","\n","train_dataset = encoded_dataset[\"train\"]\n","eval_dataset = encoded_dataset[\"validation\"]\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","    acc = accuracy_score(labels, preds)\n","    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["cc05731b76314d229e4bf1de74464231","c6a077e38890406ea1ce60865586c05c","d6b21d551c3e40c992714410919190c0","d167da468af344d1a4e54077a9269bf6","541f6a1404dd4af0bdfc110ebddeee35","7696cad188684bd19c354f088bb2d70c","693587cbb5934dab9ea976163b35da00","753bf99929784d35b1299d6378c66840","6a5aa6b7225849ec9e2d46a1df641f37","ab788078753643e991cb23a29782a908","852a969caf0c4f2097d376f14965bffe","64fe7ee2d6f84144a446fff13ec6b11b","00a0affddf894af38b662794b1f83e33","38ff27bcf35e4ea9ae1ac4fd5c6b0cd6","dc860a38ad1e43dba98c31c1d923b167","75738e2a8a1d45bdab24f35d52a1bf77","9f023fc39ccf4635a310df6e006935c2","5e160e3de1914fe4ab3c6f4bc2201523","7100629e4d0d4b2e86c8cca08bd03a77","c0eb2f7e495f47a180e87ef80488ed3b","6f68bb947557423480259effa3651c1b","9cb0db235e4c454780a618a2eaaa8967","c1261a2f183b4d0b9f562281f9c9a913","11db8716bde144719fde1594f7139855","c77d4fd7ceed44b19c66c50154885b8a","dba3b694ea9149608df4a6980308f4a9","624c450702d8403c87dc3ae150c079b8","f1abe1c8c6a249d691346720ff4193d7","0f3fb7cc7a4345d2a1af19c398325922","03e8fb8cd96945e1a727cdcb7dcbd1b4","43801b67fa194baeb1fc7ba6cd89b348","dbc58a19c64246f38933d2111a943966","0f9abcacb43e4bf89b55fbb43b22b4a4"]},"id":"RDPMdNR_Fxux","outputId":"4eb44903-8f68-4e62-f31b-cfbd433d475b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Casting the dataset:   0%|          | 0/10698 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc05731b76314d229e4bf1de74464231"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/8558 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64fe7ee2d6f84144a446fff13ec6b11b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2140 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1261a2f183b4d0b9f562281f9c9a913"}},"metadata":{}}]},{"cell_type":"code","source":["#  2 Define the Optuna objective\n","def objective(trial):\n","    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n","\n","    # Optuna suggests hyperparameters for AdamW and training\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 5e-4, log=True)\n","    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.3)\n","    batch_size = trial.suggest_categorical(\"batch_size\", [32, 48])\n","    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 2, 3)\n","\n","    training_args = TrainingArguments(\n","        output_dir=f\"./results/{trial.number}\",\n","        learning_rate=learning_rate,\n","        weight_decay=weight_decay,\n","        per_device_train_batch_size=batch_size,\n","        num_train_epochs=num_train_epochs,\n","        report_to=\"none\",\n","        # Removed evaluation_strategy, save_strategy, and logging_strategy due to TypeError\n","    )\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    # 3 Training — internally uses AdamW optimizer\n","    trainer.train()\n","    metrics = trainer.evaluate()\n","\n","    # 4 Report evaluation metric back to Optuna\n","    return metrics[\"eval_accuracy\"]\n"],"metadata":{"id":"bvikNaI_F2-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5 Run Optuna study\n","study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=20)\n","\n","print(\"Best hyperparameters:\", study.best_params)\n","print(\"Best validation accuracy:\", study.best_value)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d07b784f600543158dff979ee900e2cf","9b0a7716cfe04dcca2458a7485f6edb5","c6080593f6bb472193fd10310d338bad","c03ffd379d0a4d16b8b51eb9deb86a41","194b4d1f3f504cca962cd3c6196571f0","97543aedaa69404984a7aaa541af8e29","35b22545f10e4f0a8670f91f71d83792","b80ee31afa7146aab796d09ef2c74c91","7bc7e0f573e44e9588f194af2efa0edf","cc224fd1822f4f55a00be242327de8d6","5c55ccb4339d42e492a444cb4ee3fdd3"]},"id":"OLmK0TuvF9Q2","outputId":"3e8be1e8-5150-47d3-8d1c-8494927ba18f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 12:27:18,981] A new study created in memory with name: no-name-39aad061-fc98-41aa-b574-0ee31e087bce\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d07b784f600543158dff979ee900e2cf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='537' max='537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [537/537 04:16, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.107000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 12:31:47,378] Trial 0 finished with value: 0.9616822429906542 and parameters: {'learning_rate': 4.240581583059883e-05, 'weight_decay': 0.2367395889909453, 'batch_size': 48, 'num_train_epochs': 3}. Best is trial 0 with value: 0.9616822429906542.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [358/358 02:49, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:08]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 12:34:46,143] Trial 1 finished with value: 0.9593457943925233 and parameters: {'learning_rate': 7.466851495719788e-06, 'weight_decay': 0.09045961074739281, 'batch_size': 48, 'num_train_epochs': 2}. Best is trial 0 with value: 0.9616822429906542.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='804' max='804' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [804/804 04:23, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.422900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 12:39:19,444] Trial 2 finished with value: 0.9551401869158879 and parameters: {'learning_rate': 1.2281711771117244e-06, 'weight_decay': 0.1373073940233538, 'batch_size': 32, 'num_train_epochs': 3}. Best is trial 0 with value: 0.9616822429906542.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='537' max='537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [537/537 04:22, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.100400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 12:43:50,560] Trial 3 finished with value: 0.9663551401869159 and parameters: {'learning_rate': 7.668938387754336e-05, 'weight_decay': 0.17315718570924743, 'batch_size': 48, 'num_train_epochs': 3}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [358/358 02:52, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 12:46:51,318] Trial 4 finished with value: 0.9640186915887851 and parameters: {'learning_rate': 0.00017667311125427597, 'weight_decay': 0.03685512102513615, 'batch_size': 48, 'num_train_epochs': 2}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [358/358 02:53, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 12:49:53,866] Trial 5 finished with value: 0.9574766355140187 and parameters: {'learning_rate': 4.1520873508195074e-06, 'weight_decay': 0.10048811416241134, 'batch_size': 48, 'num_train_epochs': 2}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [358/358 02:52, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 12:52:54,784] Trial 6 finished with value: 0.9570093457943926 and parameters: {'learning_rate': 3.5750479757738046e-06, 'weight_decay': 0.12955046180009736, 'batch_size': 48, 'num_train_epochs': 2}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='537' max='537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [537/537 04:40, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.157900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 12:57:43,708] Trial 7 finished with value: 0.9579439252336449 and parameters: {'learning_rate': 0.0003444086440984969, 'weight_decay': 0.20066456199535332, 'batch_size': 48, 'num_train_epochs': 3}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='804' max='804' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [804/804 05:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.116400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:03:22,219] Trial 8 finished with value: 0.9630841121495327 and parameters: {'learning_rate': 6.427007056335462e-05, 'weight_decay': 0.21483890674356595, 'batch_size': 32, 'num_train_epochs': 3}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='804' max='804' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [804/804 05:48, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.245800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:09:19,377] Trial 9 finished with value: 0.9588785046728971 and parameters: {'learning_rate': 3.402758515363457e-06, 'weight_decay': 0.06248560753142308, 'batch_size': 32, 'num_train_epochs': 3}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='804' max='804' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [804/804 04:52, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.128400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:14:20,087] Trial 10 finished with value: 0.9635514018691589 and parameters: {'learning_rate': 2.1216940726237158e-05, 'weight_decay': 0.26995424325709333, 'batch_size': 32, 'num_train_epochs': 3}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [358/358 03:13, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:17:42,268] Trial 11 finished with value: 0.9626168224299065 and parameters: {'learning_rate': 0.00023178640101368652, 'weight_decay': 0.004789919671147086, 'batch_size': 48, 'num_train_epochs': 2}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [358/358 03:41, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:21:32,653] Trial 12 finished with value: 0.9649532710280374 and parameters: {'learning_rate': 0.00012327589313612875, 'weight_decay': 0.0018012853676639962, 'batch_size': 48, 'num_train_epochs': 2}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [358/358 03:06, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:24:47,460] Trial 13 finished with value: 0.9644859813084112 and parameters: {'learning_rate': 8.865656989651001e-05, 'weight_decay': 0.1855759569077591, 'batch_size': 48, 'num_train_epochs': 2}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='537' max='537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [537/537 05:41, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.115800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:30:37,986] Trial 14 finished with value: 0.9649532710280374 and parameters: {'learning_rate': 2.193584982652083e-05, 'weight_decay': 0.2957975017859309, 'batch_size': 48, 'num_train_epochs': 3}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [358/358 03:40, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:34:27,368] Trial 15 finished with value: 0.9644859813084112 and parameters: {'learning_rate': 0.00013277908931809564, 'weight_decay': 0.166162305195391, 'batch_size': 48, 'num_train_epochs': 2}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='537' max='537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [537/537 04:52, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.234400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:39:28,027] Trial 16 finished with value: 0.9467289719626168 and parameters: {'learning_rate': 0.0004352484290845848, 'weight_decay': 0.01574816376321602, 'batch_size': 48, 'num_train_epochs': 3}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [358/358 03:34, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:43:11,448] Trial 17 finished with value: 0.9644859813084112 and parameters: {'learning_rate': 4.023752424695986e-05, 'weight_decay': 0.10140254969464088, 'batch_size': 48, 'num_train_epochs': 2}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='536' max='536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [536/536 03:56, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.146100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:47:16,595] Trial 18 finished with value: 0.9616822429906542 and parameters: {'learning_rate': 1.2381196477439789e-05, 'weight_decay': 0.05098809348597362, 'batch_size': 32, 'num_train_epochs': 2}. Best is trial 3 with value: 0.9663551401869159.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='537' max='537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [537/537 05:39, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.099900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-11-16 13:53:04,938] Trial 19 finished with value: 0.9649532710280374 and parameters: {'learning_rate': 8.61944579407336e-05, 'weight_decay': 0.16098450700140338, 'batch_size': 48, 'num_train_epochs': 3}. Best is trial 3 with value: 0.9663551401869159.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'learning_rate': 7.668938387754336e-05, 'weight_decay': 0.17315718570924743, 'batch_size': 48, 'num_train_epochs': 3}\n","Best validation accuracy: 0.9663551401869159\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"77398ca9","outputId":"8bcac959-2333-4752-9fdc-f412bb07aa2f"},"source":["print(\"Best hyperparameters:\", study.best_params)\n","print(\"Best validation accuracy:\", study.best_value)\n","\n","# Initialize model with best hyperparameters\n","best_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n","\n","# Set the best hyperparameters\n","best_training_args = TrainingArguments(\n","    output_dir=\"./best_results\",\n","    learning_rate=study.best_params[\"learning_rate\"],\n","    weight_decay=study.best_params[\"weight_decay\"],\n","    per_device_train_batch_size=study.best_params[\"batch_size\"],\n","    num_train_epochs=study.best_params[\"num_train_epochs\"],\n","    report_to=\"none\",\n",")\n","\n","best_trainer = Trainer(\n","    model=best_model,\n","    args=best_training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Evaluate the model with the best hyperparameters\n","final_metrics = best_trainer.evaluate()\n","\n","print(\"\\nFinal Evaluation Metrics with Best Hyperparameters:\")\n","for key, value in final_metrics.items():\n","    print(f\"{key}: {value:.4f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'learning_rate': 7.668938387754336e-05, 'weight_decay': 0.17315718570924743, 'batch_size': 48, 'num_train_epochs': 3}\n","Best validation accuracy: 0.9663551401869159\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [268/268 00:08]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Final Evaluation Metrics with Best Hyperparameters:\n","eval_loss: 0.6879\n","eval_model_preparation_time: 0.0022\n","eval_accuracy: 0.5949\n","eval_precision: 0.5831\n","eval_recall: 0.5949\n","eval_f1: 0.5882\n","eval_runtime: 8.2054\n","eval_samples_per_second: 260.8030\n","eval_steps_per_second: 32.6610\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"bdd8f007","outputId":"26cf6d0b-90dc-43ed-a9f8-e587e5d5d968"},"source":["# Make predictions on the evaluation set\n","predictions = best_trainer.predict(eval_dataset)\n","\n","# Extract logits and labels from predictions\n","logits = predictions.predictions\n","labels = predictions.label_ids\n","\n","# Compute all metrics using the compute_metrics function\n","calculated_metrics = compute_metrics((logits, labels))\n","\n","print(\"\\nExplicitly Calculated Metrics on Evaluation Set:\")\n","print(f\"Accuracy: {calculated_metrics['accuracy']:.4f}\")\n","print(f\"Precision: {calculated_metrics['precision']:.4f}\")\n","print(f\"Recall: {calculated_metrics['recall']:.4f}\")\n","print(f\"F1 Score: {calculated_metrics['f1']:.4f}\")\n","\n","# Print the loss from the final evaluation metrics (if available)\n","if 'eval_loss' in final_metrics:\n","    print(f\"Loss: {final_metrics['eval_loss']:.4f}\")\n","else:\n","    print(\"Loss not available directly from final_metrics. Please refer to eval_loss in previous output.\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Explicitly Calculated Metrics on Evaluation Set:\n","Accuracy: 0.5949\n","Precision: 0.5831\n","Recall: 0.5949\n","F1 Score: 0.5882\n","Loss: 0.6879\n"]}]},{"cell_type":"code","source":["print(\"Best hyperparameters:\", study.best_params)\n","print(\"Best validation accuracy:\", study.best_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUavOXit8aUB","outputId":"ff634505-4b6e-4291-9363-bd5c4b516e9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'learning_rate': 7.668938387754336e-05, 'weight_decay': 0.17315718570924743, 'batch_size': 48, 'num_train_epochs': 3}\n","Best validation accuracy: 0.9663551401869159\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cc88c77a","outputId":"55960ff3-9eea-4c6c-b3c8-b989fd185653"},"source":["print(\"DistilBERT Metrics from calculated_metrics:\")\n","print(f\"Accuracy: {calculated_metrics['accuracy']:.4f}\")\n","print(f\"Precision: {calculated_metrics['precision']:.4f}\")\n","print(f\"Recall: {calculated_metrics['recall']:.4f}\")\n","print(f\"F1 Score: {calculated_metrics['f1']:.4f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DistilBERT Metrics from calculated_metrics:\n","Accuracy: 0.5949\n","Precision: 0.5831\n","Recall: 0.5949\n","F1 Score: 0.5882\n"]}]},{"cell_type":"markdown","metadata":{"id":"0d7fa678"},"source":["## Corrected DistilBERT Model Evaluation\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":596},"id":"1140b691","outputId":"432af1f4-2397-4539-8fbf-3535ab92d00a"},"source":["import torch\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","# Ensure the best hyperparameters are available from the Optuna study\n","if 'study' not in globals() or study is None:\n","    print(\"Error: Optuna study not found. Please run the Optuna optimization cells first.\")\n","else:\n","    print(\"Best hyperparameters:\", study.best_params)\n","    print(\"Best validation accuracy from Optuna study:\", study.best_value)\n","\n","    # Initialize model with best hyperparameters\n","    # It's crucial to initialize a new model for training if the previous one was used in the study.\n","    model_to_train = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n","\n","    # Set the best hyperparameters\n","    best_training_args = TrainingArguments(\n","        output_dir=\"./best_model_trained_results\", # Changed output directory to avoid conflicts\n","        learning_rate=study.best_params[\"learning_rate\"],\n","        weight_decay=study.best_params[\"weight_decay\"],\n","        per_device_train_batch_size=study.best_params[\"batch_size\"],\n","        num_train_epochs=study.best_params[\"num_train_epochs\"],\n","        report_to=\"none\",\n","        # Optional: Add logging/evaluation strategy if needed, but keep it minimal for re-evaluation\n","        # evaluation_strategy=\"epoch\",\n","        # save_strategy=\"epoch\",\n","        # load_best_model_at_end=True, # Requires evaluation strategy\n","    )\n","\n","    best_trainer_retrained = Trainer(\n","        model=model_to_train,\n","        args=best_training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    # Crucially, TRAIN the model with the best hyperparameters\n","    print(\"\\nTraining DistilBERT model with best hyperparameters...\")\n","    best_trainer_retrained.train()\n","    print(\"Training complete.\\n\")\n","\n","    # Evaluate the retrained model on the evaluation set\n","    final_retrained_metrics = best_trainer_retrained.evaluate()\n","\n","    print(\"\\nFinal Evaluation Metrics for **Retrained** DistilBERT Model with Best Hyperparameters:\")\n","    for key, value in final_retrained_metrics.items():\n","        print(f\"{key}: {value:.4f}\")\n","\n","    # Make predictions on the evaluation set to get precision, recall, f1 separately\n","    predictions_retrained = best_trainer_retrained.predict(eval_dataset)\n","    logits_retrained = predictions_retrained.predictions\n","    labels_retrained = predictions_retrained.label_ids\n","\n","    calculated_metrics_retrained = compute_metrics((logits_retrained, labels_retrained))\n","\n","    print(\"\\nExplicitly Calculated Metrics for Retrained DistilBERT on Evaluation Set:\")\n","    print(f\"Accuracy: {calculated_metrics_retrained['accuracy']:.4f}\")\n","    print(f\"Precision: {calculated_metrics_retrained['precision']:.4f}\")\n","    print(f\"Recall: {calculated_metrics_retrained['recall']:.4f}\")\n","    print(f\"F1 Score: {calculated_metrics_retrained['f1']:.4f}\")\n","\n","    # Save the retrained model\n","    model_to_train.save_pretrained(\"./best_distilbert_model\")\n","    tokenizer.save_pretrained(\"./best_distilbert_model\")\n","    print(\"\\nRetrained DistilBERT model and tokenizer saved to './best_distilbert_model'\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'learning_rate': 7.668938387754336e-05, 'weight_decay': 0.17315718570924743, 'batch_size': 48, 'num_train_epochs': 3}\n","Best validation accuracy from Optuna study: 0.9663551401869159\n","\n","Training DistilBERT model with best hyperparameters...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='537' max='537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [537/537 04:48, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.101000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete.\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Final Evaluation Metrics for **Retrained** DistilBERT Model with Best Hyperparameters:\n","eval_loss: 0.1229\n","eval_accuracy: 0.9654\n","eval_precision: 0.9658\n","eval_recall: 0.9654\n","eval_f1: 0.9651\n","eval_runtime: 7.6080\n","eval_samples_per_second: 281.2830\n","eval_steps_per_second: 35.2260\n","epoch: 3.0000\n","\n","Explicitly Calculated Metrics for Retrained DistilBERT on Evaluation Set:\n","Accuracy: 0.9654\n","Precision: 0.9658\n","Recall: 0.9654\n","F1 Score: 0.9651\n","\n","Retrained DistilBERT model and tokenizer saved to './best_distilbert_model'\n"]}]},{"cell_type":"markdown","metadata":{"id":"58c75e80"},"source":["## Sentiment Prediction with DistilBERT\n","\n","This code block defines a function `predict_sentiment` that takes a text input and uses the retrained DistilBERT model to classify its sentiment. Since the model was originally trained on binary (positive/negative) labels, a heuristic is applied to infer 'neutral' sentiment:\n","\n","*   If the model's highest predicted probability for either positive or negative is below a certain `confidence_threshold` (e.g., 0.6), the sentiment is classified as 'Neutral'.\n","*   Otherwise, the sentiment is classified as 'Positive' or 'Negative' based on the highest probability.\n","\n","This approach provides an estimation for 'neutral' as the model was not explicitly trained on a 'neutral' class. For more accurate 'neutral' predictions, the model would need to be re-trained with a dataset that includes a dedicated 'neutral' class."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1a977f4e","outputId":"e09e6b52-7ceb-4421-a045-76b8c8a6e8b3"},"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","import torch.nn.functional as F\n","\n","# Load the saved tokenizer and model\n","model_path = \"./best_distilbert_model\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)\n","\n","# Ensure the model is in evaluation mode\n","model.eval()\n","\n","def predict_sentiment(text, confidence_threshold=0.6):\n","    # Tokenize input text\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","\n","    # Make prediction\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    # Get probabilities by applying softmax to logits\n","    probabilities = F.softmax(outputs.logits, dim=-1)[0].tolist()\n","\n","    # Assuming 0: Negative, 1: Positive based on previous mapping\n","    negative_prob = probabilities[0]\n","    positive_prob = probabilities[1]\n","\n","    # Determine sentiment based on probabilities and threshold\n","    if positive_prob > confidence_threshold and positive_prob > negative_prob:\n","        sentiment = \"Positive\"\n","    elif negative_prob > confidence_threshold and negative_prob > positive_prob:\n","        sentiment = \"Negative\"\n","    else:\n","        sentiment = \"Neutral\"\n","\n","    return sentiment, {\"Negative_prob\": negative_prob, \"Positive_prob\": positive_prob}\n","\n","# Example usage:\n","text1 = \"This product is absolutely fantastic! I love it.\"\n","sentiment1, probs1 = predict_sentiment(text1)\n","print(f\"Text: '{text1}'\\nSentiment: {sentiment1}, Probabilities: {probs1}\\n\")\n","\n","text2 = \"I am very disappointed with this service, it was terrible.\"\n","sentiment2, probs2 = predict_sentiment(text2)\n","print(f\"Text: '{text2}'\\nSentiment: {sentiment2}, Probabilities: {probs2}\\n\")\n","\n","text3 = \"The product is okay, nothing special, just average.\"\n","sentiment3, probs3 = predict_sentiment(text3)\n","print(f\"Text: '{text3}'\\nSentiment: {sentiment3}, Probabilities: {probs3}\\n\")\n","\n","text4 = \"This is neither good nor bad, just a product.\"\n","sentiment4, probs4 = predict_sentiment(text4)\n","print(f\"Text: '{text4}'\\nSentiment: {sentiment4}, Probabilities: {probs4}\\n\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text: 'This product is absolutely fantastic! I love it.'\n","Sentiment: Positive, Probabilities: {'Negative_prob': 0.000790383608546108, 'Positive_prob': 0.9992096424102783}\n","\n","Text: 'I am very disappointed with this service, it was terrible.'\n","Sentiment: Negative, Probabilities: {'Negative_prob': 0.9949712753295898, 'Positive_prob': 0.0050287023186683655}\n","\n","Text: 'The product is okay, nothing special, just average.'\n","Sentiment: Positive, Probabilities: {'Negative_prob': 0.0011189732467755675, 'Positive_prob': 0.9988810420036316}\n","\n","Text: 'This is neither good nor bad, just a product.'\n","Sentiment: Positive, Probabilities: {'Negative_prob': 0.011385664343833923, 'Positive_prob': 0.9886143207550049}\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"06232f1b"},"source":["## Interactive Sentiment Prediction\n","\n","Use the input box below to enter text and see the DistilBERT model's sentiment prediction (Positive, Negative, or Neutral). Type `quit` to stop the interactive session."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bd6caeab","outputId":"315115aa-f1e4-4401-c589-72ebae0a870a"},"source":["while True:\n","    user_input = input(\"\\nEnter text (type 'quit' to exit): \")\n","    if user_input.lower() == 'quit':\n","        print(\"Exiting interactive prediction.\")\n","        break\n","\n","    sentiment, probabilities = predict_sentiment(user_input)\n","    print(f\"Sentiment: {sentiment}, Probabilities: {probabilities}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Enter text (type 'quit' to exit): #reallyglobe? You collect payment online but you can't do online refund? How come you have no 211 live rep to speak to with? bcoz of plandemic?!  but you wanted the customer to get refund at your store? What is the use of online banking?  Your Agent JayDetl7071..said it was ok for me to complain him for adding heat to my fire...you have no customer service globe..everytime I complaint you don't always give satisfactory resolution..#reallyglobe# Remove your customer service if they can't help us and your company to grow! Always unresolved, always unsatisfied, always bad service!\n","Sentiment: Negative, Probabilities: {'Negative_prob': 0.9985458850860596, 'Positive_prob': 0.001454177894629538}\n","\n","Enter text (type 'quit' to exit): exit\n","Sentiment: Neutral, Probabilities: {'Negative_prob': 0.49149182438850403, 'Positive_prob': 0.5085081458091736}\n","\n","Enter text (type 'quit' to exit): quit\n","Exiting interactive prediction.\n"]}]},{"cell_type":"markdown","metadata":{"id":"da96d792"},"source":["## Acquire and Preprocess Authenticity Data\n","\n","### Subtask:\n","Acquire a dataset labeled for authenticity (original vs. computer-generated) and preprocess it for DistilBERT fine-tuning, including tokenization and creating train/validation splits.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":602,"referenced_widgets":["f3a9b10bada94c2d88c5d144730705cb","6fea5512d85c4ee485a33348606da167","74f6166495c64df6944fcd70b6e7f6a0","a3c9b76def104da8aebab6a88eaa7c91","09fda26765fa4fd6aad01b818d326d72","fb37a4a6e0494fa6aa5050083292a5ae","a063457692e3409abd69c243c1ba200b","02b954ed9766457fafb3b5964831748c","234f875582284bf7b98af4b9d0fdd89d","7f4cdfd0a9264ca687e5deaf6c4eb30e","e4a7053bb02447ceb1ac2150fc8323ea","7c35c3b2ab6a4474b566c5993a5ac7c4","7ce972d8703e4012932a58120b90565d","27091ace9e564e28841cc87884da096c","4da2463133a34eb7830dd272b4e629cf","0d232079246b494884d5039a34478e91","03ee53d1dc2840d4aa7a5672028709a9","f2dcaeba9fcd4c21af27aec81490d299","c2c5fc76948747809dd4b31ac6058094","32c0f618593c4456a2c345f18c50eb8e","1c11fa59dbbd4dcaa2f31188e0d301e2","d0403ca11af446b2b23e4e93f032af77","3a8791b5be28485b8bb16d9f6922be5c","a7c4066b91c74c0080394cba1023d62f","ab77d6797a4545d4b66127e19d324e49","724556435b86447183f28207235db8ad","23ac7263c0b0438896c15a00bee2e3c3","dc21c7e1f3b043cf8f10ee72e04a377d","ecd4158e95c24f1690f87267ca80792e","e227fcd48c104b70a9550391dc7e822e","683151a29ee64c38921a0e76ecf932aa","1497fadd90ca4f0abff553a2f171bf58","53a171db91da4454be3cabc7ef84010c"]},"id":"44d1a2db","outputId":"5e899269-376a-4c26-ffcb-59745be66ecf"},"source":["import pandas as pd\n","from datasets import Dataset, DatasetDict, ClassLabel\n","from transformers import AutoTokenizer\n","\n","# 1. Identify and load the authenticity-labeled dataset\n","csv_file_path = 'Philippine_Business_TrustPilot_Reviews_Labeled.csv'\n","df = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n","\n","# 2. Rename the column containing the text content to 'sentence' and labels to 'label'\n","df = df.rename(columns={'User Review Body': 'sentence', 'Ground Label': 'label'})\n","\n","# 3. Define a label mapping and apply it. 'Positive' to 1, 'Negative' to 0, filter out 'Neutral'\n","label_mapping = {'Positive': 1, 'Negative': 0}\n","df['label'] = df['label'].map(label_mapping)\n","\n","# 4. Remove rows where 'sentence' is empty or 'label' could not be mapped\n","df = df.dropna(subset=['label', 'sentence']) # Drop rows where mapping resulted in NaN (e.g., 'Neutral')\n","df = df[df['sentence'].astype(str).str.strip() != ''] # Remove rows with empty sentences\n","df['label'] = df['label'].astype(int) # Convert labels to int after dropping NaNs\n","\n","print(f\"Dataset shape after initial cleaning and label mapping: {df.shape}\")\n","print(\"Label distribution after cleaning:\")\n","print(df['label'].value_counts())\n","\n","# 5. Convert preprocessed DataFrame into a Hugging Face `Dataset` object\n","dataset = Dataset.from_pandas(df)\n","\n","# 6. Cast the 'label' column to ClassLabel\n","# Assuming 0: Negative, 1: Positive based on previous mapping\n","features = dataset.features.copy()\n","features['label'] = ClassLabel(names=['negative', 'positive'])\n","dataset = dataset.cast(features)\n","\n","# 7. Split the `Dataset` into training and validation sets\n","train_test_split = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=42)\n","dataset_dict = DatasetDict({\n","    'train': train_test_split['train'],\n","    'validation': train_test_split['test'] # Rename 'test' to 'validation' for consistency\n","})\n","\n","print(f\"Train dataset size: {len(dataset_dict['train'])}\")\n","print(f\"Validation dataset size: {len(dataset_dict['validation'])}\")\n","\n","# 8. Initialize the `AutoTokenizer`\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","\n","# 9. Define a preprocessing function and apply it\n","def preprocess_function(examples):\n","    return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n","\n","encoded_dataset = dataset_dict.map(preprocess_function, batched=True)\n","\n","# 10. Rename the 'label' column to 'labels' and set the format to 'torch'\n","encoded_dataset = encoded_dataset.rename_column(\"label\", \"labels\")\n","encoded_dataset.set_format(\"torch\")\n","\n","print(\"Preprocessing complete. Encoded dataset example:\")\n","print(encoded_dataset[\"train\"][0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset shape after initial cleaning and label mapping: (10698, 13)\n","Label distribution after cleaning:\n","label\n","1    7181\n","0    3517\n","Name: count, dtype: int64\n"]},{"output_type":"display_data","data":{"text/plain":["Casting the dataset:   0%|          | 0/10698 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3a9b10bada94c2d88c5d144730705cb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train dataset size: 8558\n","Validation dataset size: 2140\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/8558 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c35c3b2ab6a4474b566c5993a5ac7c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2140 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a8791b5be28485b8bb16d9f6922be5c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Preprocessing complete. Encoded dataset example:\n","{'Business Name': 'Globe Telecom', 'Business Average Rating': tensor(1.1000), 'Business Review Grade': 'Bad', 'User Review Title': 'Globe Telecom Please Close Down the doors of Your company.', 'sentence': 'Globe should be closed down. I am both a gamer and an online class student. Whenever I have online classes, I will disconnect because of how much the wifi is so low, and plus There is no rain or wind that is disrupting our internet connection, Its just that the connection is really bad. Whenever I play online games such as Call of Duty Mobile, I will get a good internet connection before the game but whenever the game starts I get 199ms then I disconnect. Plus we always pay our internet bill in time then you give us a bad wifi? Well if that is how it is whats the use of even paying internet bill? I do not care about how hard you convince people that your wifi is good but the truth is you should just close down your company.', 'User Review Rating': tensor(1), 'User Review Date': 'Updated Feb 7, 2021', 'User Review Count': tensor(1), 'User  Country': 'PH', 'User Review Status': 'Updated', 'User Review Month': 'Feb', 'User Review Year': '2021', 'labels': tensor(0), '__index_level_0__': tensor(2013), 'input_ids': tensor([  101,  7595,  2323,  2022,  2701,  2091,  1012,  1045,  2572,  2119,\n","         1037, 27911,  1998,  2019,  3784,  2465,  3076,  1012,  7188,  1045,\n","         2031,  3784,  4280,  1010,  1045,  2097, 12532, 10087,  6593,  2138,\n","         1997,  2129,  2172,  1996, 15536,  8873,  2003,  2061,  2659,  1010,\n","         1998,  4606,  2045,  2003,  2053,  4542,  2030,  3612,  2008,  2003,\n","        23217,  2075,  2256,  4274,  4434,  1010,  2049,  2074,  2008,  1996,\n","         4434,  2003,  2428,  2919,  1012,  7188,  1045,  2377,  3784,  2399,\n","         2107,  2004,  2655,  1997,  4611,  4684,  1010,  1045,  2097,  2131,\n","         1037,  2204,  4274,  4434,  2077,  1996,  2208,  2021,  7188,  1996,\n","         2208,  4627,  1045,  2131, 20713,  5244,  2059,  1045, 12532, 10087,\n","         6593,  1012,  4606,  2057,  2467,  3477,  2256,  4274,  3021,  1999,\n","         2051,  2059,  2017,  2507,  2149,  1037,  2919, 15536,  8873,  1029,\n","         2092,  2065,  2008,  2003,  2129,  2009,  2003,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1])}\n"]}]},{"cell_type":"markdown","metadata":{"id":"bf420837"},"source":["## Train DistilBERT for Authenticity Classification\n","\n","### Subtask:\n","Initialize a new DistilBERT model and fine-tune it on the authenticity-labeled dataset using the best hyperparameters found by Optuna.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"58cea18e","outputId":"47d4064b-4248-47ec-c452-9fb0b9311245"},"source":["import torch\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","# Ensure the best hyperparameters are available from the Optuna study\n","if 'study' not in globals() or study is None:\n","    print(\"Error: Optuna study not found. Please run the Optuna optimization cells first.\")\n","else:\n","    print(\"Best hyperparameters from Optuna study:\", study.best_params)\n","    print(\"Best validation accuracy from Optuna study:\", study.best_value)\n","\n","    # 1. Initialize AutoModelForSequenceClassification\n","    # It's crucial to initialize a new model for training, as the Optuna study models were transient.\n","    model_for_authenticity_classification = AutoModelForSequenceClassification.from_pretrained(\n","        \"distilbert-base-uncased\",\n","        num_labels=2 # Assuming binary classification: Original vs. Computer-Generated\n","    )\n","\n","    # 2. Create a TrainingArguments object using best hyperparameters\n","    best_training_args_authenticity = TrainingArguments(\n","        output_dir=\"./distilbert_authenticity_fine_tuned_model\", # New output directory for this task\n","        learning_rate=study.best_params[\"learning_rate\"],\n","        weight_decay=study.best_params[\"weight_decay\"],\n","        per_device_train_batch_size=study.best_params[\"batch_size\"],\n","        num_train_epochs=study.best_params[\"num_train_epochs\"],\n","        report_to=\"none\"\n","    )\n","\n","    # 3. Instantiate a Trainer object\n","    authenticity_trainer = Trainer(\n","        model=model_for_authenticity_classification,\n","        args=best_training_args_authenticity,\n","        train_dataset=encoded_dataset[\"train\"], # Use the preprocessed authenticity train dataset\n","        eval_dataset=encoded_dataset[\"validation\"], # Use the preprocessed authenticity validation dataset\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    # 4. Call the train() method to start fine-tuning\n","    print(\"\\nStarting fine-tuning of DistilBERT for authenticity classification...\")\n","    authenticity_trainer.train()\n","    print(\"Fine-tuning complete.\\n\")\n","\n","    # Evaluate the fine-tuned model\n","    authenticity_metrics = authenticity_trainer.evaluate()\n","\n","    print(\"\\nEvaluation Metrics for Fine-tuned DistilBERT on Authenticity Dataset:\")\n","    for key, value in authenticity_metrics.items():\n","        print(f\"{key}: {value:.4f}\")\n","\n","    # Save the fine-tuned model and tokenizer\n","    authenticity_trainer.save_model(\"./distilbert_authenticity_fine_tuned_model\")\n","    tokenizer.save_pretrained(\"./distilbert_authenticity_fine_tuned_model\")\n","    print(\"\\nFine-tuned DistilBERT model and tokenizer for authenticity saved to './distilbert_authenticity_fine_tuned_model'\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best hyperparameters from Optuna study: {'learning_rate': 7.668938387754336e-05, 'weight_decay': 0.17315718570924743, 'batch_size': 48, 'num_train_epochs': 3}\n","Best validation accuracy from Optuna study: 0.9663551401869159\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Starting fine-tuning of DistilBERT for authenticity classification...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='98' max='537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 98/537 00:43 < 03:17, 2.22 it/s, Epoch 0.54/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]}]}